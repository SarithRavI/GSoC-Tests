{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f8108b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\envs\\tensorflow_learning\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model, model_from_json, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Lambda, Resizing, MaxPooling2D, SeparableConv2D, UpSampling2D, BatchNormalization, Input, GlobalAveragePooling2D\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "520b4738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272',\n",
       " 'QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet',\n",
       " 'QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540',\n",
       " 'QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet',\n",
       " 'QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494',\n",
       " 'QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet',\n",
       " 'SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5',\n",
       " 'SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86aae928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "electron_dataset = h5py.File(\"../dataset/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\",\"r\")\n",
    "electron_imgs=np.array(electron_dataset[\"X\"])\n",
    "electron_labels=np.array(electron_dataset[\"y\"],dtype=np.int64)\n",
    "\n",
    "photon_dataset = h5py.File(\"../dataset/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\",\"r\")\n",
    "photon_imgs=np.array(photon_dataset[\"X\"])\n",
    "photon_labels=np.array(photon_dataset[\"y\"],dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d39bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arrs = np.vstack((photon_imgs,electron_imgs))\n",
    "labels = np.hstack((photon_labels,electron_labels)).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb51eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(img_arrs.shape[0]*0.7) if img_arrs.shape[0]%10==0 else int(img_arrs.shape[0]*0.7)+1 \n",
    "num_val_test = img_arrs.shape[0] - num_train\n",
    "num_val = int(num_val_test*(2/3)) if num_val_test%3==0 else int(num_val_test*(2/3))+1\n",
    "num_test =num_val_test-num_val \n",
    "\n",
    "split_seed =42\n",
    "\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(img_arrs, labels,\n",
    "                                                            test_size=num_val_test, train_size =num_train, \n",
    "                                                            random_state=split_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test,\n",
    "                                                test_size=num_test, train_size =num_val,\n",
    "                                                random_state=split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de2dfe2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_dataset=  np.array(list(transformImages(X_train,\"train\").as_numpy_iterator()))\n",
    "# train_labels= getLabels(y_train,\"train\")\n",
    "\n",
    "# train_dataset = SingleElectronPhotonDataset(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81228092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputs,mean=0.5,std=0.5,size=96):\n",
    "    x = Lambda(lambda inputs: (inputs - mean) /std)(inputs)\n",
    "    x = Resizing(size,size)(x)\n",
    "    return x\n",
    "    \n",
    "def forward_pass(inputs,num_middle_blocks =8,num_classes=2):\n",
    "    \n",
    "    # Begin of entry flow\n",
    "    x = Conv2D(32, 3, strides = 2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    Z = x\n",
    "    \n",
    "    for size in [128, 256, 728]:\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(size, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(size, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "        \n",
    "        # skip connection\n",
    "        residual = Conv2D(size, 1, strides=2, padding='same')(Z)\n",
    "        residual = BatchNormalization()(residual)\n",
    "        x += residual \n",
    "        \n",
    "        Z = x\n",
    "        \n",
    "     # Begin of middle flow\n",
    "    for _ in range(num_middle_blocks) :\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x += Z\n",
    "        Z = x\n",
    "        \n",
    "    # Begin of exist flow \n",
    "    x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(1024, 3, padding='same')(x) \n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # skip connection\n",
    "    residual = Conv2D(1024, 1, strides=2, padding='same')(Z)\n",
    "    residual = BatchNormalization()(residual)\n",
    "    x += residual\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(1024, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    act = 'softmax'\n",
    "    if num_classes == 1:\n",
    "        act = 'sigmoid'\n",
    "    output = Dense(num_classes, activation=act)(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d36fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 32, 2))\n",
    "outputs = forward_pass(\n",
    "    preprocess(inputs,\n",
    "               mean=0.5,std=0.5,size=96),\n",
    "    num_middle_blocks=8,num_classes=1\n",
    ")\n",
    "model = Model(inputs, outputs,name=\"xception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd82eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0\n",
    "checkpoint_dir = \"../models/tf-ckpts/{model}\".format(model=model.name)\n",
    "checkpoints = os.listdir(checkpoint_dir)\n",
    "checkpoint = list(filter(lambda i : \".ckpt\" in i, checkpoints))\n",
    "\n",
    "checkpoint_path = checkpoint_dir+\"/cp-{epoch}.ckpt\" \n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "if len(checkpoint)>0:\n",
    "    initial_epoch = sorted([int(ck.split(\".\")[0].split(\"-\")[1]) for ck in checkpoint])[-1] \n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b41634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 750/5447 [===>..........................] - ETA: 3:41:03 - loss: 0.6539 - auc: 0.6587"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=2, batch_size=64, validation_data=(X_val, y_val),initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4657b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
