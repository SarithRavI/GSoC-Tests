{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33cd6609",
   "metadata": {},
   "source": [
    "This notebook contains the Tensorflow Keras implementation of the Xception model.\n",
    "Refer this paper for Xception model specification: https://arxiv.org/pdf/1610.02357.pdf\n",
    "\n",
    "It's worth noting this keras implementation is same as the pytorch implementation of Xception model, except for here we output only one scalar probability. In case of pytorch implementation we output two scalar probabilities (softmax). This small difference is due to unavailability of multi class AUC metric in tf/keras (https://github.com/tensorflow/addons/issues/265). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f8108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model, model_from_json, Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, \n",
    "    Activation, \n",
    "    Conv2D, \n",
    "    Lambda, \n",
    "    Resizing, \n",
    "    MaxPooling2D, \n",
    "    SeparableConv2D, \n",
    "    BatchNormalization, \n",
    "    Input, \n",
    "    GlobalAveragePooling2D\n",
    ")\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c84d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# extracted this code snippet from tensorflow documentation\n",
    "# this will enable GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520b4738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272',\n",
       " 'QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272.test.snappy.parquet',\n",
       " 'QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540',\n",
       " 'QCDToGGQQ_IMGjet_RH1all_jet0_run1_n47540.test.snappy.parquet',\n",
       " 'QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494',\n",
       " 'QCDToGGQQ_IMGjet_RH1all_jet0_run2_n55494.test.snappy.parquet',\n",
       " 'quark-gluon_data-set_n139306.hdf5',\n",
       " 'SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5',\n",
       " 'SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86aae928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "electron_dataset = h5py.File(\"../dataset/SingleElectronPt50_IMGCROPS_n249k_RHv1.hdf5\",\"r\")\n",
    "electron_imgs=np.array(electron_dataset[\"X\"])\n",
    "electron_labels=np.array(electron_dataset[\"y\"],dtype=np.int64)\n",
    "\n",
    "photon_dataset = h5py.File(\"../dataset/SinglePhotonPt50_IMGCROPS_n249k_RHv1.hdf5\",\"r\")\n",
    "photon_imgs=np.array(photon_dataset[\"X\"])\n",
    "photon_labels=np.array(photon_dataset[\"y\"],dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d39bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arrs = np.vstack((photon_imgs,electron_imgs))\n",
    "labels = np.hstack((photon_labels,electron_labels)).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb51eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(img_arrs.shape[0]*0.7) if img_arrs.shape[0]%10==0 else int(img_arrs.shape[0]*0.7)+1 \n",
    "num_val_test = img_arrs.shape[0] - num_train\n",
    "num_val = int(num_val_test*(2/3)) if num_val_test%3==0 else int(num_val_test*(2/3))+1\n",
    "num_test =num_val_test-num_val \n",
    "\n",
    "split_seed =42\n",
    "\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(img_arrs, labels,\n",
    "                                                            test_size=num_val_test, train_size =num_train, \n",
    "                                                            random_state=split_seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test,\n",
    "                                                test_size=num_test, train_size =num_val,\n",
    "                                                random_state=split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81228092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputs,mean=0.5,std=0.5,size=96):\n",
    "    x = Lambda(lambda inputs: (inputs - mean) /std)(inputs)\n",
    "    x = Resizing(size,size)(x)\n",
    "    return x\n",
    "    \n",
    "def forward_pass(inputs,num_middle_blocks =8,num_classes=2):\n",
    "    \n",
    "    # Begin of entry flow\n",
    "    x = Conv2D(32, 3, strides = 2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    Z = x\n",
    "    \n",
    "    for size in [128, 256, 728]:\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(size, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(size, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "        \n",
    "        # skip connection\n",
    "        residual = Conv2D(size, 1, strides=2, padding='same')(Z)\n",
    "        residual = BatchNormalization()(residual)\n",
    "        x += residual \n",
    "        \n",
    "        Z = x\n",
    "        \n",
    "     # Begin of middle flow\n",
    "    for _ in range(num_middle_blocks) :\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation('relu')(x)\n",
    "        x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "        x += Z\n",
    "        Z = x\n",
    "        \n",
    "    # Begin of exist flow \n",
    "    x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(1024, 3, padding='same')(x) \n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # skip connection\n",
    "    residual = Conv2D(1024, 1, strides=2, padding='same')(Z)\n",
    "    residual = BatchNormalization()(residual)\n",
    "    x += residual\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(728, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(1024, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    act = 'softmax'\n",
    "    if num_classes == 1:\n",
    "        act = 'sigmoid'\n",
    "    output = Dense(num_classes, activation=act)(x)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4d36fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 32, 2))\n",
    "outputs = forward_pass(\n",
    "    preprocess(inputs,\n",
    "               mean=0.5,std=0.5,size=96),\n",
    "    num_middle_blocks=8,num_classes=1\n",
    ")\n",
    "model = Model(inputs, outputs,name=\"xception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd82eb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0\n",
    "checkpoint_dir = \"../models/tf-ckpts/{model}\".format(model=model.name)\n",
    "checkpoints = os.listdir(checkpoint_dir)\n",
    "checkpoint = list(filter(lambda i : \".ckpt\" in i, checkpoints))\n",
    "\n",
    "checkpoint_path = checkpoint_dir+\"/cp-{epoch}.ckpt\" \n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "if len(checkpoint)>0:\n",
    "    initial_epoch = sorted([int(ck.split(\".\")[0].split(\"-\")[1]) for ck in checkpoint])[-1] \n",
    "    latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b41634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n",
      "10894/10894 [==============================] - ETA: 0s - loss: 0.6030 - auc: 0.7351\n",
      "Epoch 1: saving model to ../models/tf-ckpts/xception\\cp-1.ckpt\n",
      "10894/10894 [==============================] - 3604s 330ms/step - loss: 0.6030 - auc: 0.7351 - val_loss: 0.6616 - val_auc: 0.7585\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=23, batch_size=32, validation_data=(X_val, y_val),\n",
    "                    initial_epoch=initial_epoch,callbacks=cp_callback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
