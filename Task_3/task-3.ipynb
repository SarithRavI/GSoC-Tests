{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0500e110",
   "metadata": {},
   "source": [
    "This file contains GNN based solution for specific task of project [Graph Neural Networks for End-to-End Particle Identification with the CMS Experiment](https://docs.google.com/document/d/1lWTSASnVICm_4Zof7wr6_LkS24P_Z8TR1px_tctemQI/edit).\n",
    "\n",
    "GNN layers been used:\n",
    "\n",
    "- [Graph Convolution Layer](https://arxiv.org/pdf/1609.02907.pdf)\n",
    "\n",
    "- [PointNet Convolution Layer](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.PointNetConv.html#torch_geometric.nn.conv.PointNetConv) \n",
    "\n",
    "In both, model architecture is composed of two layers.\n",
    "Latent embedding dimension is set to 300.\n",
    "\n",
    "Node features:\n",
    "- Channel values\n",
    "- Global Positional encoding (3D coordinates of the nodes) - optional\n",
    "\n",
    "Edge features:\n",
    "- Euclidean distance between nodes.\n",
    "\n",
    "Both models are trained for 75 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448f0897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch_geometric.nn import MessagePassing,GPSConv, GINEConv\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import degree\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.classification import MulticlassAUROC, MulticlassAccuracy\n",
    "\n",
    "from dataset import JetsGraphsDataset\n",
    "from torch_geometric.nn.conv import GATConv,PointNetConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b4e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GIN convolution along the graph structure\n",
    "class GINConv(MessagePassing):\n",
    "    def __init__(self, emb_dim,input_node_dim,input_edge_dim):\n",
    "\n",
    "        super(GINConv, self).__init__(aggr = \"add\")\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), torch.nn.BatchNorm1d(2*emb_dim), \n",
    "                                       torch.nn.ReLU(), torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "        self.eps = torch.nn.Parameter(torch.Tensor([0]))\n",
    "        self.linear = torch.nn.Linear(input_node_dim, emb_dim)\n",
    "        self.edge_encoder = torch.nn.Linear(input_edge_dim, emb_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.linear(x)\n",
    "        edge_embedding = self.edge_encoder(edge_attr)\n",
    "        out = self.mlp((1 + self.eps) *x + self.propagate(edge_index, x=x, edge_attr=edge_embedding))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return F.relu(x_j + edge_attr)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "### GCN convolution along the graph structure\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, emb_dim,input_node_dim,input_edge_dim):\n",
    "        super(GCNConv, self).__init__(aggr='add')\n",
    "        \n",
    "        self.linear = torch.nn.Linear(input_node_dim, emb_dim)\n",
    "        self.root_emb = torch.nn.Embedding(1, emb_dim)\n",
    "        self.edge_encoder = torch.nn.Linear(input_edge_dim, emb_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.linear(x)\n",
    "        edge_embedding = self.edge_encoder(edge_attr)\n",
    "\n",
    "        row, col = edge_index\n",
    "\n",
    "        #edge_weight = torch.ones((edge_index.size(1), ), device=edge_index.device)\n",
    "        deg = degree(row, x.size(0), dtype = x.dtype) + 1\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return self.propagate(edge_index, x=x, edge_attr = edge_embedding, norm=norm) + F.relu(x + self.root_emb.weight) * 1./deg.view(-1,1)\n",
    "\n",
    "    def message(self, x_j, edge_attr, norm):\n",
    "        return norm.view(-1, 1) * F.relu(x_j + edge_attr)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e07b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(torch.nn.Module):\n",
    "    def __init__(self,input_node_dim,emb_dim):\n",
    "        super(mlp, self).__init__()\n",
    "        self.mlp = torch.nn.Sequential(torch.nn.Linear(input_node_dim, 2*emb_dim), \n",
    "                                       torch.nn.BatchNorm1d(2*emb_dim), \n",
    "                                       torch.nn.ReLU(), \n",
    "                                       torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "    def forward(self,x):\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePasssing_Module(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    MessagePasssing_Module contains 2 or more GNN layers stacked.\n",
    "    Output:\n",
    "        node representations\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layer, input_node_dim, input_edge_dim, emb_dim,extraPE_dim=None,\n",
    "                 extraPE_method='sum', drop_ratio = 0.5, JK = \"last\", residual = False, gnn_type = 'gin'):\n",
    "        '''\n",
    "            emb_dim (int): node embedding dimensionality\n",
    "            num_layer (int): number of GNN message passing layers\n",
    "        '''\n",
    "        super(MessagePasssing_Module, self).__init__()\n",
    "        \n",
    "        self.gnn_type = gnn_type\n",
    "        self.num_layer = num_layer\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        self.input_node_dim = input_node_dim\n",
    "        self.input_edge_dim = input_edge_dim\n",
    "        ### add residual connection or not\n",
    "        self.residual = residual\n",
    "        self.extraPE_dim = extraPE_dim\n",
    "        self.extraPE_method = extraPE_method\n",
    "\n",
    "        if self.num_layer < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        ### List of GNNs\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "        \n",
    "        if extraPE_dim:\n",
    "            # this is to transform random walk encoding\n",
    "            self.extraPE_Encoder = torch.nn.Linear(self.extraPE_dim,self.input_node_dim)\n",
    "        \n",
    "        if extraPE_dim and extraPE_method=='cat':\n",
    "            self.input_node_dim *= 2\n",
    "            \n",
    "        for layer in range(num_layer):\n",
    "            if layer == 0:\n",
    "                if gnn_type == 'gin':\n",
    "                    self.convs.append(GINConv(emb_dim,input_node_dim=self.input_node_dim,input_edge_dim=self.input_edge_dim))\n",
    "                elif gnn_type == 'gcn':\n",
    "                    self.convs.append(GCNConv(emb_dim,input_node_dim=self.input_node_dim,input_edge_dim=self.input_edge_dim))\n",
    "                elif gnn_type == 'gat':\n",
    "                    self.convs.append(GATConv(in_channels=self.input_node_dim,out_channels=emb_dim,edge_dim=self.input_edge_dim))\n",
    "                elif gnn_type == \"pointnet\":\n",
    "                    local_mlp = mlp(self.input_node_dim+3, emb_dim)\n",
    "                    global_mlp = None\n",
    "                    self.convs.append(PointNetConv(local_mlp,global_mlp))\n",
    "                    \n",
    "                elif gnn_type == \"gps\":\n",
    "                    # we need to explicitly declare this mlp\n",
    "                    nn = torch.nn.Sequential(torch.nn.Linear(self.input_node_dim, 2*emb_dim),\n",
    "                                           torch.nn.BatchNorm1d(2*emb_dim), \n",
    "                                           torch.nn.ReLU(), \n",
    "                                           torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "                    self.convs.append(GPSConv(self.input_node_dim, GINEConv(nn,edge_dim =self.input_edge_dim), \n",
    "                                              heads=5, attn_dropout=0.3))\n",
    "                else:\n",
    "                    raise ValueError('Undefined GNN type called {}'.format(gnn_type))\n",
    "                \n",
    "            else:\n",
    "                if gnn_type == 'gin':\n",
    "                    self.convs.append(GINConv(emb_dim,input_node_dim=emb_dim,input_edge_dim=self.input_edge_dim))\n",
    "                elif gnn_type == 'gcn':\n",
    "                    self.convs.append(GCNConv(emb_dim,input_node_dim=emb_dim,input_edge_dim=self.input_edge_dim))\n",
    "                elif gnn_type == 'gat':\n",
    "                    self.convs.append(GATConv(in_channels=emb_dim,out_channels=emb_dim,edge_dim=self.input_edge_dim))\n",
    "                elif gnn_type == \"pointnet\":\n",
    "                    local_mlp = mlp(emb_dim+3, emb_dim)\n",
    "                    global_mlp = None\n",
    "                    self.convs.append(PointNetConv(local_mlp,global_mlp))\n",
    "                    \n",
    "                elif gnn_type == \"gps\":\n",
    "                    # we need to explicitly declare this mlp\n",
    "                    nn = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), \n",
    "                                       torch.nn.BatchNorm1d(2*emb_dim), \n",
    "                                       torch.nn.ReLU(), \n",
    "                                       torch.nn.Linear(2*emb_dim, emb_dim))\n",
    "                    self.convs.append(GPSConv(emb_dim, GINEConv(nn,edge_dim =self.input_edge_dim),\n",
    "                                              heads=5, attn_dropout=0.3))\n",
    "                else:\n",
    "                    raise ValueError('Undefined GNN type called {}'.format(gnn_type))\n",
    "\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        \n",
    "        x = batched_data.x\n",
    "        edge_index = batched_data.edge_index\n",
    "        edge_attr = batched_data.edge_attr\n",
    "        pos = batched_data.pos\n",
    "        batch = batched_data.batch\n",
    "        \n",
    "        if self.extraPE_dim:\n",
    "            extraPE = batched_data.extraPE\n",
    "            extraPE_emb = self.extraPE_Encoder(extraPE)\n",
    "            if self.extraPE_method == 'sum':\n",
    "                h_list = [x+extraPE_emb]\n",
    "            elif self.extraPE_method == 'cat':\n",
    "                h_list = [torch.cat((x,extraPE_emb),1)]      \n",
    "        else:    \n",
    "            h_list = [x]  \n",
    "            \n",
    "        for layer in range(self.num_layer):\n",
    "            if self.gnn_type == 'pointnet':\n",
    "                h = self.convs[layer](h_list[layer], pos, edge_index)\n",
    "            elif self.gnn_type == 'gps':\n",
    "                h = self.convs[layer](h_list[layer], edge_index,batch=batch,edge_attr=edge_attr)\n",
    "            else:    \n",
    "                h = self.convs[layer](h_list[layer], edge_index, edge_attr)\n",
    "                \n",
    "            h = self.batch_norms[layer](h)\n",
    "\n",
    "            if layer == self.num_layer - 1:\n",
    "                #remove relu for the last layer\n",
    "                h = F.dropout(h, self.drop_ratio, training = self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\n",
    "\n",
    "            if self.residual:\n",
    "                h += h_list[layer]\n",
    "\n",
    "            h_list.append(h)\n",
    "\n",
    "        ### Different implementations of Jk-concat\n",
    "        if self.JK == \"last\":\n",
    "            node_representation = h_list[-1]\n",
    "        elif self.JK == \"sum\":\n",
    "            node_representation = 0\n",
    "            for layer in range(self.num_layer + 1):\n",
    "                node_representation += h_list[layer]\n",
    "\n",
    "        return node_representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098a0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2, num_layer = 5,num_pre_fnn_layers =0,num_post_fnn_layers =1,hasPos =True,num_coords=3, \n",
    "                 input_spec_fts_dim=3,input_edge_dim = 1, emb_dim = 300,extraPE_dim=None,extraPE_method = 'sum', gnn_type = 'gcn', \n",
    "                 residual = False, drop_ratio = 0.5, JK = \"last\", graph_pooling = \"mean\"):\n",
    "        '''\n",
    "            hasPos (bool) : whether input node features should contain global positioning embeded\n",
    "                            ps: global positioning is the coordinate of the pixel on 2D grid.\n",
    "            input_spec_fts_dim (int) : denotes number of specific features (features apart from postional embedding)\n",
    "            num_coords : number of coordinates required for the positional embedding \n",
    "            extraPE_dim: Denotes dimension of random walk  or Laplacian eigenvector positional encoding\n",
    "            extraPE_method: Denotes how random walk embeddings or Laplacian eigenvector positional encoding should be embedded \n",
    "                         cat - concatenation, sum - summation.\n",
    "        '''\n",
    "        \n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.gnn_type = gnn_type\n",
    "        self.num_layer = num_layer\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hasPos = hasPos\n",
    "        self.num_coords =num_coords\n",
    "        self.num_classes = num_classes\n",
    "        self.num_pre_fnn_layers = num_pre_fnn_layers\n",
    "        self.num_post_fnn_layers = num_post_fnn_layers\n",
    "        self.graph_pooling = graph_pooling\n",
    "        self.input_spec_fts_dim = input_spec_fts_dim\n",
    "        self.input_edge_dim = input_edge_dim\n",
    "        self.extraPE_method = extraPE_method\n",
    "        \n",
    "        if self.gnn_type==\"pointnet\":\n",
    "            self.hasPos = False\n",
    "        \n",
    "        self.pos_kwd = \"hasPos\"\n",
    "        if not self.hasPos:\n",
    "            self.pos_kwd = \"noPos\"\n",
    "            \n",
    "        if not self.hasPos:\n",
    "            self.input_node_dim = self.input_spec_fts_dim\n",
    "        else:\n",
    "            self.input_node_dim = self.input_spec_fts_dim+num_coords\n",
    "\n",
    "        if self.num_layer < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "            \n",
    "        if self.num_post_fnn_layers < 1:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than or equal to 1.\")\n",
    "        \n",
    "        self.graph_pred_pre_linear_list = torch.nn.ModuleList()\n",
    "        \n",
    "        # dimention of node fts which are fed into message passing layers\n",
    "        self.input_node_dim_mp = self.input_node_dim\n",
    "        \n",
    "        if self.num_pre_fnn_layers >0:\n",
    "            self.graph_pred_pre_linear_list.append(torch.nn.Linear(self.input_node_dim, emb_dim))\n",
    "            for i in range(1,num_pre_fnn_layers):\n",
    "                self.graph_pred_pre_linear_list.append(torch.nn.Linear(emb_dim, emb_dim))\n",
    "            self.input_node_dim_mp = emb_dim\n",
    "                 \n",
    "        ### GNN to generate node embeddings\n",
    "        self.gnn_node = MessagePasssing_Module(num_layer,input_node_dim=self.input_node_dim_mp,\n",
    "                                               input_edge_dim = self.input_edge_dim, emb_dim=emb_dim,\n",
    "                                               extraPE_dim = extraPE_dim, extraPE_method = self.extraPE_method,\n",
    "                                               JK = JK, drop_ratio = drop_ratio, residual = residual, \n",
    "                                               gnn_type = gnn_type)\n",
    "\n",
    "        ### Pooling function to generate entire-graph embeddings\n",
    "        if self.graph_pooling == \"sum\":\n",
    "            self.pool = global_add_pool\n",
    "        elif self.graph_pooling == \"mean\":\n",
    "            self.pool = global_mean_pool\n",
    "        elif self.graph_pooling == \"max\":\n",
    "            self.pool = global_max_pool\n",
    "        elif self.graph_pooling == \"attention\":\n",
    "            self.pool = GlobalAttention(gate_nn = torch.nn.Sequential(torch.nn.Linear(emb_dim, 2*emb_dim), \n",
    "                                                                      torch.nn.BatchNorm1d(2*emb_dim), torch.nn.ReLU(),\n",
    "                                                                      torch.nn.Linear(2*emb_dim, 1)))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid graph pooling type.\")\n",
    "\n",
    "        self.graph_pred_post_linear_list = torch.nn.ModuleList()\n",
    "\n",
    "        for i in range(num_post_fnn_layers-1):\n",
    "            self.graph_pred_post_linear_list.append(torch.nn.Linear(emb_dim, emb_dim))\n",
    "        self.graph_pred_post_linear_list.append(torch.nn.Linear(emb_dim, self.num_classes))\n",
    "                \n",
    "\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "\n",
    "        input_x = batched_data.x # here we can split the x \n",
    "        \n",
    "        batched_data.pos = input_x[:,self.input_spec_fts_dim:] # this will keep pos embeddings\n",
    "        input_x = input_x[:,:self.input_node_dim]\n",
    "        prep_x = input_x\n",
    "        \n",
    "        #preprocessing node features (only). \n",
    "        for fnn_inx in range(self.num_pre_fnn_layers):\n",
    "            prep_x = self.graph_pred_pre_linear_list[fnn_inx](prep_x)\n",
    "        \n",
    "        batched_data.x = prep_x\n",
    "        \n",
    "        h_node = self.gnn_node(batched_data)\n",
    "\n",
    "        h_graph = self.pool(h_node, batched_data.batch)\n",
    "\n",
    "        output = h_graph # initial input is set to the output of the GNN \n",
    "        \n",
    "        #postprocessing graph embeddings (only). \n",
    "        for fnn_inx in range(self.num_post_fnn_layers):\n",
    "            output = self.graph_pred_post_linear_list[fnn_inx](output)\n",
    "            \n",
    "\n",
    "        return F.softmax(output,dim=1)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.gnn_type+f\"-model-{self.pos_kwd}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3081f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbad78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multicls_criterion = torch.nn.CrossEntropyLoss()\n",
    "epochs = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41243fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(name,transform=None, pre_transform=None,pre_filter=None):\n",
    "    return JetsGraphsDataset('../dataset/',name=name,transform=transform,\n",
    "                             pre_transform=pre_transform,pre_filter=pre_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a3fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(dataset):\n",
    "    # random splitting dataset\n",
    "    train_inx, valid_inx, test_inx = random_split(range(len(dataset)),[0.7,0.2,0.1],generator=torch.Generator()\n",
    "                                                .manual_seed(42))\n",
    "\n",
    "    train_dataloader = DataLoader(dataset[list(train_inx)], batch_size=4, shuffle=True)\n",
    "    valid_dataloader = DataLoader(dataset[list(valid_inx)], batch_size=4, shuffle=False)\n",
    "    test_dataloader = DataLoader(dataset[list(test_inx)], batch_size=4, shuffle=False)\n",
    "    \n",
    "    return train_dataloader,valid_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd072fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, loader, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    loss_accum = 0\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch=batch.to(device)\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else: \n",
    "            output = model(batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss = multicls_criterion(output, batch.y.view(-1).to(torch.int64))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        loss_accum += loss.item()\n",
    "\n",
    "    print('Average training loss: {}'.format(loss_accum / (step + 1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc7e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, loader,evaluator= \"roauc\"):\n",
    "    model.eval()\n",
    "    \n",
    "    preds_list = []\n",
    "    target_list = []\n",
    "    for step, batch in enumerate(loader):\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(batch)\n",
    "            preds_list.extend(output.tolist())\n",
    "        target_list += batch.y.view(-1).tolist()\n",
    "\n",
    "    if evaluator == \"roauc\":   \n",
    "        metric = MulticlassAUROC(num_classes=2, average=\"macro\", thresholds=None)\n",
    "    if evaluator == \"acc\":\n",
    "        metric = MulticlassAccuracy(num_classes=2, average=\"macro\")\n",
    "    # print(\"AUC-ROC metric score : \",metric(torch.Tensor(preds_list),torch.Tensor(target_list)).item())\n",
    "    return metric(torch.Tensor(preds_list),torch.Tensor(target_list).to(torch.int64)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685faee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,optimizer,dataset):\n",
    "    checkpoints_path = \"../models\"\n",
    "    checkpoints = os.listdir(checkpoints_path)\n",
    "    checkpoint_path = list(filter(lambda i : str(model) in i, checkpoints))\n",
    "    \n",
    "    train_curves = []\n",
    "    valid_curves = []\n",
    "    starting_epoch = 1 \n",
    "    \n",
    "    # create loaders \n",
    "    train_dataloader,valid_dataloader,test_dataloader = create_loaders(dataset)\n",
    "    \n",
    "    if len(checkpoint_path)>0:\n",
    "        checkpoint = torch.load(f\"{checkpoints_path}/{checkpoint_path[0]}\")\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        starting_epoch = checkpoint['epoch']+1\n",
    "\n",
    "    for epoch in range(starting_epoch, epochs + 1):\n",
    "        print(\"=====Epoch {}\".format(epoch))\n",
    "        print('Training...')\n",
    "        train(model, device, train_dataloader, optimizer)\n",
    "        \n",
    "        # save checkpoint of current epoch\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, f\"{checkpoints_path}/{str(model)}-{epoch}.pt\")\n",
    "\n",
    "        # delete checkpoint of previous epoch\n",
    "        if epoch>1:\n",
    "            os.remove(f\"{checkpoints_path}/{str(model)}-{epoch-1}.pt\")\n",
    "\n",
    "        print(\"Evaluating...\")\n",
    "        train_perf_roauc = evaluate(model,device,train_dataloader)\n",
    "        valid_perf_roauc = evaluate(model,device,valid_dataloader)\n",
    "        print('ROAUC scores: ',{'Train': train_perf_roauc, 'Validation': valid_perf_roauc})\n",
    "        \n",
    "    print('\\nFinished training!')\n",
    "    print('\\nROAUC Test score: {}'.format(evaluate(model,device,test_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ddca3",
   "metadata": {},
   "source": [
    "## Training PointNet Conv based GNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1312d6c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pointnet_model = GNN(num_classes = 2, num_layer = 2,num_post_fnn_layers=2,input_edge_dim = 1,num_coords=3, \n",
    "                 input_spec_fts_dim=3,gnn_type = 'pointnet', emb_dim = 300, drop_ratio = 0.3).to(device)\n",
    "optimizer = optim.Adam(pointnet_model.parameters(), lr=1e-3)\n",
    "\n",
    "train_model(pointnet_model,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d2189e",
   "metadata": {},
   "source": [
    "## Training of GCN based model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff4573",
   "metadata": {},
   "source": [
    "### Training with GPE (all x,y,z coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814e59f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gcn_model = GNN(num_classes = 2, num_layer = 2,num_post_fnn_layers=2,hasPos=True,input_edge_dim = 1,num_coords=3, \n",
    "                input_spec_fts_dim=3, gnn_type = 'gcn', emb_dim = 300, drop_ratio = 0.3).to(device)\n",
    "optimizer = optim.Adam(gcn_model.parameters(), lr=1e-3)\n",
    "\n",
    "train_model(gcn_model,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ce459d",
   "metadata": {},
   "source": [
    "### Training with GPE (only x,y coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20322d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gcn_model = GNN(num_classes = 2, num_layer = 2,num_post_fnn_layers=2,hasPos=True,input_edge_dim = 1,num_coords=2, \n",
    "                input_spec_fts_dim=3, gnn_type = 'gcn', emb_dim = 300, drop_ratio = 0.3).to(device)\n",
    "optimizer = optim.Adam(gcn_model.parameters(), lr=1e-3)\n",
    "\n",
    "train_model(gcn_model,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bff0df",
   "metadata": {},
   "source": [
    "### Training without GPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d7131e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gcn_model = GNN(num_classes = 2, num_layer = 2,num_post_fnn_layers=2,hasPos=False,input_edge_dim = 1, \n",
    "            input_spec_fts_dim=3, gnn_type = 'gcn', emb_dim = 300, drop_ratio = 0.3).to(device)\n",
    "optimizer = optim.Adam(gcn_model.parameters(), lr=1e-3)\n",
    "\n",
    "train_model(gcn_model,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc8537",
   "metadata": {},
   "source": [
    "### Training with deeper model (with 10 GCN layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be61d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_model = GNN(num_classes = 2, num_layer = 5,num_post_fnn_layers=2,hasPos=True,input_edge_dim = 1,num_coords=2, \n",
    "                input_spec_fts_dim=3, gnn_type = 'gcn', emb_dim = 100, drop_ratio = 0.3, JK='sum').to(device)\n",
    "optimizer = optim.Adam(gcn_model.parameters(), lr=1e-3)\n",
    "\n",
    "train_model(gcn_model,optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6ac06a",
   "metadata": {},
   "source": [
    "### Training GPS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f88aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset for GPS \n",
    "transform = T.AddRandomWalkPE(walk_length=20, attr_name='extraPE') # adding random walk positional encoding\n",
    "jets_dataset = import_dataset(name=\"QCDToGGQQ_IMGjet_RH1all_jet0_run0_n36272\",\n",
    "                             transform=transform)\n",
    "\n",
    "GPS_model = GNN(num_classes = 2, num_layer = 5,num_pre_fnn_layers=1,num_post_fnn_layers=2,hasPos=True,input_edge_dim = 1,num_coords=2, \n",
    "                input_spec_fts_dim=3, gnn_type = 'gps', emb_dim = 300, extraPE_dim=20, drop_ratio = 0.3).to(device)\n",
    "optimizer = optim.Adam(GPS_model.parameters(), lr=1e-3)\n",
    "\n",
    "train_model(GPS_model,optimizer,jets_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
